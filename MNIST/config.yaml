use_owl: False
use_growl: True
use_group_lasso: False
use_mask: True

# weight decay
use_wd: False
wd: 0.05

n_input: 784
n_class: 10

batch_size: 128
num_epochs: 300
# Retraining
retraining: True
num_epochs_retrain: 100

learning_rate: 0.0001
learning_rate_decay_factor: 0.96
num_epochs_per_decay: 10

# OWL params setup
# the type of OWL parameters, currently we are using OSCAR, but other types
# may be implemented in the future
# reg_params_type: 'OSCAR' # options: OSCAR, PLD
reg_params_type: 'PLD'
PLD_transition: 0.3 # the ratio of linear decreasing region. If use 0, then use the number of rows which is equal to the row number of the layer with minimum rows
preference: 0.6
owl_applied_layers: [True, False, False, False, False]
# owl_applied_layers: [False, True, True, True, False]
prox_update_iter: False # if set to true, will update every iterations, otherwise every epoch

# regularization parameters support value for OSCAR type
# w = \lambda_{1} + \lamdba_{2}(n-i)
# number of sublists is equal to the total number of layers
# the first element in each list is \lambda_{1}, the second element is \lambda_{2}

# CNN 64-32 parameters
# owl_params: [[1.5e1, 5e-2], [1.6e1, 5e-2], [2.2e0, 1e-2], [1.5e1, 5e-2], [1e-1, 1e-3]]
# growl_params: [[1e-1, 5e-2], [1e-1, 5e-3], [1e-1, 1e-2], [1e-1, 2.5e-2], [1e-1, 1e-3]]

# Single hidden layer or 300-100 layer
growl_params: [[1e-20, 1e-20], [3e-1, 3e-3], [1e1, 1e-2], [1e1, 1e-2], [1e-1, 1e-3]]


grid_search_reg_params: False

# convolutional filter regularization type
# 1: regularization across neurons
# 2: regularization acorss channels in each neuron
# many other possibilities exists!!!
conv_reg_type: 3 #[1,2,3,4] corresponding with [channel_growl, input_depth_growl, filter_growl, arbitrary_filter]
# Retraining related
similarity: 'norm_euclidean' # current options: cosine, euclidean, norm_euclidean

#
mask_update_freq: 1
display_prune_total: True
display_similarity: 50
row_norm_freq: 50

# % if turned on, then perform clustering every display_similarity epochs, otherwise only do the clustering at the end training. Turn this off to speed up training when there are many rows.
# train_cluster: False

plot_dir: '../../results/plots/mnist/12_05/single/wd/'

summary_dir: '../../results/summaries/mnist/12_05/single/wd/'

tensorboard_freq: 200
